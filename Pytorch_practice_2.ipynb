{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Z0d11udqDtv-nttuFuVx3krWbNacNZqD",
      "authorship_tag": "ABX9TyPMvfPoK88U82EtLrlXQx3+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandhrabijoy/_/blob/master/Pytorch_practice_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9vgDqJ8TVEVh"
      },
      "outputs": [],
      "source": [
        "import numpy as np,pandas as pd ,pylab as pl\n",
        "import h5py,torch\n",
        "from tensorflow import image as timage\n",
        "from torchvision import transforms,utils\n",
        "from torch.utils.data import DataLoader as tdl\n",
        "from torch.utils.data import Dataset as tds\n",
        "import torch.nn as tnn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magic import register_line_magic\n",
        "dev=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "ZoH_DDNaVfpV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TData(tds):\n",
        "  def __init__(self,X,y):\n",
        "    self.X=torch.tensor(X,dtype=torch.float32)\n",
        "    self.y=torch.tensor(y,dtype=torch.int32)\n",
        "  def __getitem__(self,index):\n",
        "    train_img,train_lbl=self.X[index],self.y[index]\n",
        "    return train_img,train_lbl\n",
        "  def __len__(self):\n",
        "    return self.y.shape[0]"
      ],
      "metadata": {
        "id": "dHn9-Hi0Ym90"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG19(tnn.Module):\n",
        "  def __init__(self,num_classes):\n",
        "    super(VGG19,self).__init__()\n",
        "    self.block1=tnn.Sequential(\n",
        "        tnn.Conv2d(in_channels=3,out_channels=64,kernel_size=(3,3),stride=(1,1),padding=1),\n",
        "        tnn.ReLU(),\n",
        "        tnn.Conv2d(in_channels=64,out_channels=64,kernel_size=(3,3),stride=(1,1),padding=1),\n",
        "        tnn.ReLU(),\n",
        "        tnn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "    )\n",
        "    self.block2=tnn.Sequential(\n",
        "        tnn.Conv2d(in_channels=64,out_channels=128,kernel_size=(3,3),stride=(1,1),padding=1),\n",
        "        tnn.ReLU(),\n",
        "        tnn.Conv2d(in_channels=128,out_channels=128,kernel_size=(3,3),stride=(1,1),padding=1),\n",
        "        tnn.ReLU(),\n",
        "        tnn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "    )\n",
        "    self.block3=tnn.Sequential(\n",
        "        tnn.Conv2d(in_channels=128,out_channels=256,kernel_size=(3,3),stride=(1,1),padding=1),\n",
        "        tnn.ReLU(),\n",
        "        tnn.Conv2d(in_channels=256,out_channels=256,kernel_size=(3,3),stride=(1,1),padding=1),\n",
        "        tnn.ReLU(),\n",
        "        tnn.Conv2d(in_channels=256,out_channels=256,kernel_size=(3,3),stride=(1,1),padding=1),\n",
        "        tnn.ReLU(),\n",
        "        tnn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "    )\n",
        "    self.block4=tnn.Sequential(\n",
        "        tnn.Conv2d(in_channels=256,out_channels=512,kernel_size=(3,3),stride=(1,1),padding=1),\n",
        "        tnn.ReLU(),\n",
        "        tnn.Conv2d(in_channels=512,out_channels=512,kernel_size=(3,3),stride=(1,1),padding=1),\n",
        "        tnn.ReLU(),\n",
        "        tnn.Conv2d(in_channels=512,out_channels=512,kernel_size=(3,3),stride=(1,1),padding=1),\n",
        "        tnn.ReLU(),\n",
        "        tnn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "    )\n",
        "    self.block5=tnn.Sequential(\n",
        "        tnn.Conv2d(in_channels=512,out_channels=512,kernel_size=(3,3),stride=(1,1),padding=1),\n",
        "        tnn.ReLU(),\n",
        "        tnn.Conv2d(in_channels=512,out_channels=512,kernel_size=(3,3),stride=(1,1),padding=1),\n",
        "        tnn.ReLU(),\n",
        "        tnn.Conv2d(in_channels=512,out_channels=512,kernel_size=(3,3),stride=(1,1),padding=1),\n",
        "        tnn.ReLU(),\n",
        "        tnn.Conv2d(in_channels=512,out_channels=512,kernel_size=(3,3),stride=(1,1),padding=1),\n",
        "        tnn.ReLU(),\n",
        "        tnn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
        "    )\n",
        "\n",
        "    self.classifier=tnn.Sequential(\n",
        "        tnn.Linear(512,4096),\n",
        "        tnn.ReLU(True),\n",
        "        tnn.Linear(4096,4096),\n",
        "        tnn.ReLU(True),\n",
        "        tnn.Linear(4096,num_classes)\n",
        "    )\n",
        "    for m in self.modules():\n",
        "      if isinstance(m,torch.nn.Conv2d):\n",
        "        m.weight.detach().normal_(0,.05)\n",
        "        if m.bias is not None:\n",
        "          m.bias.detach().zero_()\n",
        "      elif isinstance(m,torch.nn.Linear):\n",
        "        m.weight.detach().normal_(0,.05)\n",
        "        m.bias.detach().detach().zero_()\n",
        "  def forward(self,x):\n",
        "    x=self.block1(x)\n",
        "    x=self.block2(x)\n",
        "    x=self.block3(x)\n",
        "    x=self.block4(x)\n",
        "    x=self.block5(x)\n",
        "\n",
        "    logits=self.classifier(x.view(-1,512))\n",
        "    probs=tnn.functional.softmax(logits,dim=1)\n",
        "    return logits,probs"
      ],
      "metadata": {
        "id": "akvtvvefZk5A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_display(x_train,y_train,x_test,y_test,pixels):\n",
        "  x_train=np.array(timage.resize(x_train,[pixels,pixels]))\n",
        "  x_test=np.array(timage.resize(x_test,[pixels,pixels]))\n",
        "\n",
        "  N=len(y_train);shuffle_ids=np.arange(N)\n",
        "  np.random.RandomState(12).shuffle(shuffle_ids)\n",
        "  x_train,y_train=x_train[shuffle_ids],y_train[shuffle_ids]\n",
        "\n",
        "  N=len(y_test);shuffle_ids=np.arange(N)\n",
        "  np.random.RandomState(23).shuffle(shuffle_ids)\n",
        "  x_test,y_test=x_test[shuffle_ids],y_test[shuffle_ids]\n",
        "\n",
        "  x_train=x_train.reshape(-1,3,pixels,pixels)\n",
        "  x_test=x_test.reshape(-1,3,pixels,pixels)\n",
        "  n=int(len(x_test/2))\n",
        "\n",
        "  x_valid,y_valid=x_test[:n],y_test[:n]\n",
        "  x_test,y_test=x_test[n:],y_test[n:]\n",
        "\n",
        "  df=pd.DataFrame([[x_train.shape,x_valid.shape,x_test.shape],\n",
        "                   [x_train.dtype,x_valid.dtype,x_test.dtype],\n",
        "                   [y_train.shape,y_valid.shape,y_test.shape],\n",
        "                   [y_train.dtype,y_valid.dtype,y_test.dtype]],\n",
        "                  columns=['train','valid','test'],\n",
        "                  index=['image shape','image type','label shape','label type'])\n",
        "  display(df)\n",
        "  return[[x_train,x_valid,x_test],[y_train,y_valid,y_test]]\n",
        "def display_examples(data_loader,pixels):\n",
        "  for images,labels in data_loader:\n",
        "    print('Image dimensions:%s'%str(images.shape))\n",
        "    print('Label dimensions:%s'%str(labels.shape))\n",
        "\n",
        "    n=np.random.randint(1,50)\n",
        "    fig=pl.figure(figsize=(11,4))\n",
        "    for i in range(n,n+5):\n",
        "      ax=fig.add_subplot(1,5,i-n+1,\\\n",
        "                         xticks=[],yticks=[],title=labels[i].item())\n",
        "      ax.imshow((images[i]).reshape(pixels,pixels,3))\n",
        "    break\n",
        "def model_acc(model,data_loader):\n",
        "  correct_preds,num_examples=0,0\n",
        "  for features,targets in data_loader:\n",
        "    features=features.to(dev)\n",
        "    targets=targets.to(dev)\n",
        "    logits,probs=model(features)\n",
        "    _,pred_labels=torch.max(probs,1)\n",
        "    num_examples+=targets.size(0)\n",
        "    correct_preds+=(pred_labels==targets).sum()\n",
        "  return correct_preds.float()/num_examples*100"
      ],
      "metadata": {
        "id": "Pe-xMU3_fbuq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@register_line_magic\n",
        "def train_run(epochs):\n",
        "  epochs=int(epochs)\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for batch_ids,(features,targets) in enumerate(train_loader):\n",
        "      features=features.to(dev);targets=targets.to(dev)\n",
        "      logits,probs=model(features)\n",
        "      cost=tnn.functional.cross_entropy(logits,targets.long())\n",
        "      optimizer.zero_grad();cost.backward()\n",
        "      optimizer.step()\n",
        "      if not batch_ids%50:\n",
        "        print('Epochs:%03d/%03d |Batch:%03d/%03d|Cost:%.4f'%(epoch+1,epochs,batch_ids,len(train)//batch_size,cost))\n",
        "        model.eval()\n",
        "        with torch.set_grad_enabled(False):\n",
        "          print('Epoch:%03d/%03d train acc:%.2f%% valid acc:%.2f%%'%\\\n",
        "                (epoch+1,epochs,\n",
        "                 model_acc(model,train_loader),\n",
        "                 model_acc(model,valid_loader)))\n",
        "\n",
        "@register_line_magic\n",
        "def print_acc(n):\n",
        "  if int(n)==1:\n",
        "    data_loader=\\\n",
        "    [train_loader,valid_loader,test_loader]\n",
        "  print('Train accuracy:%.4f%%'%\\\n",
        "        (model_acc(model,data_loader[0])))\n",
        "  print('Valid accuracy:%.4f%%'%\\\n",
        "        (model_acc(model,data_loader[1])))\n",
        "  print('Test accuracy:%.4f%%'%\\\n",
        "   (model_acc(model,data_loader[2])))"
      ],
      "metadata": {
        "id": "OAu7A2t3hmHw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "vzheGB7DfZH8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QQv0kyigX3A",
        "outputId": "d7ad38f5-d220-4020-a168-8722b008cab1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DATA\n",
        "pixels = 48\n",
        "fpath = '/content/drive/MyDrive/'\n",
        "f = 'CatDogImages.h5'\n",
        "\n",
        "# Load the file\n",
        "f = h5py.File(fpath+f , 'r')\n",
        "keys = list(f.keys())\n",
        "print(keys)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPUxr_ttzFkP",
        "outputId": "df56307e-24c0-4d15-e721-cf604a96e518"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test_images', 'test_labels', 'train_images', 'train_labels']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PDPwRH-K4SsU"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}